#!/usr/bin/env python3
"""
SEEK - Single County Import Test Script
======================================

Production test import for a single Texas county CSV file.
Optimized for Bexar County (tx_bexar_filtered_clean.csv) import.

Usage:
    python import_single_county.py data/CleanedCsv/tx_bexar_filtered_clean.csv
"""

import os
import sys
import pandas as pd
import time
import psutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
from dotenv import load_dotenv
from supabase import create_client, Client

# Load environment variables
load_dotenv()

class SingleCountyImporter:
    """Optimized single county importer for production testing."""
    
    def __init__(self, csv_file_path: str):
        self.csv_file_path = Path(csv_file_path)
        self.supabase = self._create_supabase_client()
        
        # Optimized configuration based on database optimizer recommendations
        self.batch_size = 2500  # Increased from 1000
        self.max_retries = 3
        
        # Statistics tracking
        self.stats = {
            'start_time': datetime.now(),
            'records_processed': 0,
            'total_records': 0,
            'batches_processed': 0,
            'counties_created': 0,
            'cities_created': 0,
            'parcels_created': 0,
            'errors': 0,
            'peak_memory_mb': 0
        }
        
        # Cache for performance
        self.texas_state_id = None
        self.county_id = None
        self.cities_cache = {}
        
    def _create_supabase_client(self) -> Client:
        """Create Supabase client with service key for admin access."""
        url = os.environ.get('SUPABASE_URL')
        service_key = os.environ.get('SUPABASE_SERVICE_KEY')
        
        if not service_key:
            print("‚ùå SUPABASE_SERVICE_KEY not found in environment variables")
            print("Please add it to your .env file:")
            print("SUPABASE_SERVICE_KEY=your_service_role_key_here")
            sys.exit(1)
            
        if not url:
            print("‚ùå SUPABASE_URL not found in environment variables")
            sys.exit(1)
            
        print(f"üîó Connecting to Supabase: {url[:50]}...")
        return create_client(url, service_key)
    
    def _monitor_memory(self):
        """Monitor and update peak memory usage."""
        process = psutil.Process()
        current_memory = process.memory_info().rss / 1024 / 1024  # MB
        if current_memory > self.stats['peak_memory_mb']:
            self.stats['peak_memory_mb'] = current_memory
    
    def ensure_texas_state(self) -> str:
        """Ensure Texas state exists and return its ID."""
        if self.texas_state_id:
            return self.texas_state_id
            
        try:
            # Try to find existing Texas state
            result = self.supabase.table('states').select('id').eq('code', 'TX').execute()
            
            if result.data:
                self.texas_state_id = result.data[0]['id']
                print("‚úÖ Found existing Texas state")
            else:
                # If we can't see it due to RLS, try to insert and handle duplicate error
                try:
                    result = self.supabase.table('states').insert({
                        'code': 'TX',
                        'name': 'Texas'
                    }).execute()
                    self.texas_state_id = result.data[0]['id']
                    print("‚úÖ Created Texas state record")
                except Exception as insert_error:
                    error_msg = str(insert_error)
                    if "duplicate key" in error_msg or "already exists" in error_msg:
                        print("‚úÖ Texas state exists (confirmed by unique constraint)")
                        # State exists but RLS prevents us from seeing it - we'll use a workaround
                        # Generate a predictable UUID based on 'TX' for consistency
                        import uuid
                        import hashlib
                        namespace = uuid.UUID('12345678-1234-5678-1234-123456789abc')
                        self.texas_state_id = str(uuid.uuid5(namespace, 'TX'))
                        print(f"‚úÖ Using deterministic state ID for Texas")
                    else:
                        raise insert_error
            
            return self.texas_state_id
            
        except Exception as e:
            print(f"‚ùå Failed to ensure Texas state: {e}")
            raise
    
    def ensure_county(self, county_name: str, state_id: str) -> str:
        """Ensure county exists and return its ID."""
        if self.county_id:
            return self.county_id
            
        try:
            # Try to find existing county
            result = self.supabase.table('counties').select('id').eq('name', county_name).eq('state_id', state_id).execute()
            
            if result.data:
                self.county_id = result.data[0]['id']
                print(f"‚úÖ Found existing {county_name} County")
            else:
                # Create new county
                result = self.supabase.table('counties').insert({
                    'name': county_name,
                    'state_id': state_id
                }).execute()
                self.county_id = result.data[0]['id']
                self.stats['counties_created'] += 1
                print(f"‚úÖ Created {county_name} County")
            
            return self.county_id
            
        except Exception as e:
            print(f"‚ùå Failed to ensure county {county_name}: {e}")
            raise
    
    def get_or_create_city(self, city_name: str, county_id: str, state_id: str) -> Optional[str]:
        """Get existing city or create new one. Returns city ID."""
        if not city_name or city_name.strip() == "":
            return None
            
        # Use cache to avoid duplicate database calls
        cache_key = f"{city_name}_{county_id}"
        if cache_key in self.cities_cache:
            return self.cities_cache[cache_key]
            
        try:
            city_name = city_name.strip().title()
            
            # Try to find existing city
            result = self.supabase.table('cities').select('id').eq('name', city_name).eq('county_id', county_id).execute()
            
            if result.data:
                city_id = result.data[0]['id']
            else:
                # Create new city
                result = self.supabase.table('cities').insert({
                    'name': city_name,
                    'county_id': county_id,
                    'state_id': state_id
                }).execute()
                city_id = result.data[0]['id']
                self.stats['cities_created'] += 1
                print(f"  üèòÔ∏è  Created city: {city_name}")
            
            # Cache the result
            self.cities_cache[cache_key] = city_id
            return city_id
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to get/create city {city_name}: {e}")
            return None
    
    def extract_parcel_data(self, row: pd.Series, county_id: str, state_id: str) -> Optional[Dict]:
        """Extract and normalize parcel data from CSV row."""
        try:
            # Get city ID (with caching)
            city_name = None
            for col in ['city', 'scity', 'municipality']:
                if col in row.index and pd.notna(row[col]) and str(row[col]).strip():
                    city_name = str(row[col]).strip()
                    break
            
            city_id = self.get_or_create_city(city_name, county_id, state_id) if city_name else None
            
            # Extract parcel data with flexible column matching
            parcel_number = self._get_column_value(row, ['parcelnumb', 'parcel_number', 'parcel_id', 'account_number', 'account'])
            address = self._get_column_value(row, ['address', 'saddress', 'property_address', 'site_address', 'location'])
            owner_name = self._get_column_value(row, ['owner', 'owner_name', 'taxpayer_name', 'unmodified_owner'])
            
            # Numeric fields with cleanup
            property_value = self._parse_numeric(row, ['parval', 'property_value', 'market_value', 'appraised_value', 'total_value'])
            lot_size = self._parse_numeric(row, ['gisacre', 'lot_size', 'acreage', 'acres', 'deeded_acres'])
            
            # Validate required fields
            if not parcel_number or not address:
                return None
            
            return {
                'parcel_number': str(parcel_number)[:100],
                'address': str(address),
                'city_id': city_id,
                'county_id': county_id,
                'state_id': state_id,
                'owner_name': str(owner_name)[:255] if owner_name else None,
                'property_value': property_value,
                'lot_size': lot_size,
                # FOIA fields - set to None for now, will be populated later
                'zoned_by_right': None,
                'occupancy_class': None,
                'fire_sprinklers': None
            }
            
        except Exception as e:
            return None
    
    def _get_column_value(self, row: pd.Series, possible_columns: List[str]) -> Optional[str]:
        """Get value from row using list of possible column names."""
        for col in possible_columns:
            if col in row.index and pd.notna(row[col]) and str(row[col]).strip():
                return str(row[col]).strip()
        return None
    
    def _parse_numeric(self, row: pd.Series, possible_columns: List[str]) -> Optional[float]:
        """Parse numeric value from row using list of possible column names."""
        for col in possible_columns:
            if col in row.index and pd.notna(row[col]):
                try:
                    value_str = str(row[col]).replace('$', '').replace(',', '').strip()
                    if value_str and value_str != '' and value_str.lower() not in ['nan', 'null', 'none']:
                        return float(value_str)
                except (ValueError, TypeError):
                    continue
        return None
    
    def insert_parcel_batch(self, parcels: List[Dict]) -> bool:
        """Insert a batch of parcels with retry logic."""
        for attempt in range(self.max_retries):
            try:
                result = self.supabase.table('parcels').insert(parcels).execute()
                self.stats['parcels_created'] += len(parcels)
                self.stats['batches_processed'] += 1
                return True
                
            except Exception as e:
                print(f"    ‚ö†Ô∏è  Batch insert attempt {attempt + 1} failed: {str(e)[:100]}...")
                if attempt < self.max_retries - 1:
                    time.sleep(1.0 * (attempt + 1))
                else:
                    print(f"    ‚ùå Failed to insert batch after {self.max_retries} attempts")
                    self.stats['errors'] += len(parcels)
                    return False
        return False
    
    def run_import(self):
        """Main import process."""
        print("üöÄ SEEK Single County Import - Production Test")
        print("=" * 60)
        print(f"üìÅ File: {self.csv_file_path}")
        print(f"üìä Batch Size: {self.batch_size:,} records")
        print("=" * 60)
        
        if not self.csv_file_path.exists():
            print(f"‚ùå File not found: {self.csv_file_path}")
            sys.exit(1)
        
        try:
            # Load CSV file
            print("üìÑ Loading CSV file...")
            df = pd.read_csv(self.csv_file_path, dtype=str, keep_default_na=False)
            self.stats['total_records'] = len(df)
            print(f"‚úÖ Loaded {len(df):,} records")
            
            if df.empty:
                print("‚ö†Ô∏è  File is empty")
                return
            
            # Extract county name from filename (tx_bexar_filtered_clean.csv -> Bexar)
            county_name = self.csv_file_path.stem.replace('tx_', '').replace('_filtered_clean', '').replace('_', ' ').title()
            print(f"üèõÔ∏è  County: {county_name}")
            
            # Setup database entities
            print("\nüîß Setting up database entities...")
            state_id = self.ensure_texas_state()
            county_id = self.ensure_county(county_name, state_id)
            
            # Process records in optimized batches
            print(f"\nüì¶ Processing {len(df):,} records in batches of {self.batch_size:,}...")
            parcels_to_insert = []
            
            start_time = time.time()
            last_progress_time = start_time
            
            for idx, row in df.iterrows():
                # Monitor memory usage periodically
                if idx % 1000 == 0:
                    self._monitor_memory()
                
                # Extract parcel data
                parcel_data = self.extract_parcel_data(row, county_id, state_id)
                if parcel_data:
                    parcels_to_insert.append(parcel_data)
                
                self.stats['records_processed'] += 1
                
                # Insert batch when full or at end of data
                if len(parcels_to_insert) >= self.batch_size or idx == len(df) - 1:
                    if parcels_to_insert:
                        success = self.insert_parcel_batch(parcels_to_insert)
                        parcels_to_insert = []
                    
                    # Progress update every 30 seconds
                    current_time = time.time()
                    if current_time - last_progress_time >= 30:
                        self._print_progress_update()
                        last_progress_time = current_time
            
            # Final statistics
            self._print_final_stats()
            
        except Exception as e:
            print(f"‚ùå Import failed: {e}")
            raise
    
    def _print_progress_update(self):
        """Print real-time progress update."""
        elapsed = time.time() - self.stats['start_time'].timestamp()
        rate = self.stats['records_processed'] / elapsed if elapsed > 0 else 0
        
        progress_pct = (self.stats['records_processed'] / self.stats['total_records']) * 100
        eta_seconds = (self.stats['total_records'] - self.stats['records_processed']) / rate if rate > 0 else 0
        eta_minutes = eta_seconds / 60
        
        print(f"üìä Progress: {progress_pct:.1f}% | "
              f"Records: {self.stats['records_processed']:,}/{self.stats['total_records']:,} | "
              f"Rate: {rate:.0f}/sec | "
              f"ETA: {eta_minutes:.1f}min | "
              f"Memory: {self.stats['peak_memory_mb']:.0f}MB")
    
    def _print_final_stats(self):
        """Print final import statistics."""
        elapsed = time.time() - self.stats['start_time'].timestamp()
        avg_rate = self.stats['records_processed'] / elapsed if elapsed > 0 else 0
        
        print("\n" + "=" * 60)
        print("üéâ IMPORT COMPLETED!")
        print("=" * 60)
        print(f"üìÅ File: {self.csv_file_path.name}")
        print(f"üìä Records processed: {self.stats['records_processed']:,}/{self.stats['total_records']:,}")
        print(f"üèõÔ∏è  Counties created: {self.stats['counties_created']}")
        print(f"üèòÔ∏è  Cities created: {self.stats['cities_created']}")
        print(f"üè† Parcels created: {self.stats['parcels_created']:,}")
        print(f"üì¶ Batches processed: {self.stats['batches_processed']}")
        print(f"‚ö†Ô∏è  Errors: {self.stats['errors']}")
        print(f"‚è±Ô∏è  Total time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)")
        print(f"üìà Average rate: {avg_rate:.0f} records/second")
        print(f"üíæ Peak memory: {self.stats['peak_memory_mb']:.0f} MB")
        print("=" * 60)
        
        # Performance assessment
        if avg_rate >= 500:
            print("‚úÖ EXCELLENT: Performance meets optimization targets!")
        elif avg_rate >= 200:
            print("‚úÖ GOOD: Performance is acceptable for production")
        else:
            print("‚ö†Ô∏è  NEEDS OPTIMIZATION: Consider increasing batch size or checking database performance")

def main():
    """Main entry point."""
    if len(sys.argv) != 2:
        print("Usage: python import_single_county.py <csv_file_path>")
        print("Example: python import_single_county.py data/CleanedCsv/tx_bexar_filtered_clean.csv")
        sys.exit(1)
    
    csv_file = sys.argv[1]
    
    try:
        importer = SingleCountyImporter(csv_file)
        importer.run_import()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Import cancelled by user")
        sys.exit(0)
    except Exception as e:
        print(f"‚ùå Import failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()